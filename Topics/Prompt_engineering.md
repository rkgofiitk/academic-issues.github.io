# P-Hacking in AI for Non-Replicable Research 

Generative AI works by creating new text, images or videos by training from a massive amount of data. It 
learns patterns from those data and generates similar content. The principle
of extension is the key feature to generative AI. It cannot generate vacously. From the point of view of an 
user's interaction generative AI appear to be a dialogue based 
programming interface. Many experts view that this prompt-based interface is an extension to 
[test and debugging interface](https://dl.acm.org/doi/pdf/10.1145/3673861) for the domain
of machine learning. There are two main concerns about the interface. 
- The prompt-based interface is rather loose and unoptimized
- It may, therefore, generate rather risky outputs

The question that AI experts need to ponder about is that 
- Whether they would risk on building critical application on top of generative AI model

The problem with prompting stems from the fact that it is not same as being able to communicate in natural 
language. When we communicate in natural language, the collaborators or the partners do understand inherent 
subtleness verbal conversation; and when they don't clarifications are sought. In human conversation, 
perceived intent in speaker's utterance plays and important role. It is extremely critical to understand
the intent. Double entendre is often used in political discourse. So, extension of true natural language
prompting could create confusion for users of generative AI tools. It may lead to similar near catastrophic
results as exhibited by heuritics driven soft computing methods even after lots of training.

Prompt-hacking could add or excerbate the problem obfuscating the intent in user's query. A recent article
by [Morris](https://dl.acm.org/doi/pdf/10.1145/3673861) argues that "p-hacking" could be main reason 
for "replication crisis" in AI research. She observes that social sciences already experiencing 
p-hacking crisis. She hastens to add that her observation should not be viewed to imply that social
science researchers intentially engaging in "neferious intent". However, I believe much of her observation
may extend equally well in Indian context. The Indian retraction rate is 44 per million papers which
is more than 2.5 times of average rate. It is true that the high retraction rate is not entirely be
due to generative AI, because the tool is a fairly recent additon in search kit of researchers. I
believe the replication crisis could actually lead to a drop in retraction rate. Because the researchers
may carefully craft prompts to extract their desired results.  

The question is how do we address this seemingly invincible technique? Plagiarism detection tools are 
clearly inadequate to deal with p-hacking.  

