# Role of Indian IT Companies in the Development of AGI Tools

Earlier, late last year, Nandan Nelikani said that [Indian IT companies should not invest time and money in building LLM tools like ChatGPT
or Deep Seek](https://timesofindia.indiatimes.com/business/india-business/india-shouldnt-build-another-llm-nandan-nilekani/articleshow/116269605.cms).
Building a foundational model like ChatGPT is prohibitively expensive, requiring upwards of 500 million USD. Nilekani argued if 
Indian Companies have 500 million USD to invest; they should instead use it for building computing infrastructure and AI cloud.
These are material for AI growth engines. The real challenge lies in making the tool scalable 
and affordable. With the release of Deep Seek and the cost of building AI tools falling, [Nelikani revised his stand in 
February 2025](https://economictimes.indiatimes.com/news/new-updates/why-infosys-co-founder-nandan-nilekani-feels-india-dont-need-a-china-type-deepseek-ai/articleshow/118528515.cms?from=mdr). 
Both Nilekani and Narayanmurthy Infosys co-founders agree that Indian tech companies have the expertise to build a foundational
LLM tools like ChatGPT as the cost has come down. However, going through a realistic estimate, it does not add up to back
Deep Seek's official story is that its development cost is just 5.6 million USD. The amount, in all fairness, represents only
training costs. In 2019, Deep Seek founders spent 27.8 million USD to buy 1100 GPUs; they invested approximately 138 million 
USD in 2021 for developing their supercomputer cluster named Fire-Fly-2. So, the estimated infrastructure support cost alone 
could be more than 200 million USD. That may imply a total estimated cost anywhere in the range of 500 million to 1 billion USD. Usually,
the cost of research, human resources, maintenance, electricity, cooling system, and extensive experiments for building such a 
product are many times more than pure infrastructure cost. Both the captains of IT industries in India may want to 
review their stance more cautiously than over-enthusiastically. 

[Manish Gupta, the head of Google research group in India](https://economictimes.indiatimes.com/tech/technology/google-research-india-head-disagrees-with-nandan-nilekani-says-india-must-build-llms/articleshow/115627015.cms) has been critical of Nandal Nelikani's view 
that India should not invest on foundational AI research. Manish thinks foundational research is more critical, generating
many out-of-the-box ideas to formulate use cases. He cites Aadhar as an example to prove the point that Nelikani himself created bases for
Aadhar rather than creating any associated tool as a test case. I gathered the following information about the contribution of
Manish Gupta's team in AI research from [Perplexity chatbot](https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research).
- [Matryoshka representation learning inspired by Russian nesting dolls](https://doi.org/10.48550/arXiv.2205.13147)
- In making AI more affordable and accessible to rural masses in India
- Working for developing multimodal AI representation models over 100 indic languages,
- Working with AI startups to leverage insight from Google Deepmind
- Want researchers to develop breakthrough methods for advancing fusion energy leveraging AI
- Piloting IndicGenBench and supporting researchers as a leader
   
Manish Gupta is not one of the authors of either Matryoksha or [IndicGenBench](https://arxiv.org/pdf/2404.16816) paper. 
The first paper's authors are drawn from Harvard University, Google Research, and the University of Washington. Four of them are from 
Google Research, who may belong to Manish Gupta's team. The authors of the second paper are from Google India Research. I am stating the 
facts I found different from the Perplexity search engine. The research inspired by the Russian Nesting Doll is an overstatement. The 
Peplexity's claim research paper that reported Matryoksha Representation
The learning paper uses the Nesting Russian Dolls as a metaphor to explain the model. Any nesting involves varying
degrees of granularity. It is a generic paradigm of gradual refinement of granularity of information and is independent of the Russian 
Nesting Dolls. Based on Manish Gupta's contributions and his position as a Senior Research Director in the Google Deepmind project
in India, I think his opinion carries weight and has to be taken seriously. I concur with Manish that any foundational research
trains students with the capabilities to develop cases without the limits of an example-based framework independently. No doubt both
Nilekani and Narayanmurthy, as successful founders of IT businesses in India, have established themselves as key voices among policymakers 
in the area. In comparison, Manish is younger and has not become an independent entrepreneur. So, the intent
in discussing Manish's background in the blog comes from having the experience and knowledge to proffer an opinion 
contrary to Nilekani's. 

I think the Indian Government AI Initiative aims to create an AI ecosystem. It is up to individual research groups and startups to 
use the infrastructure as they wish. In other words, the government's approach is more in line with the "Sky is the limit"  for the 
pursuit of ideas in the development of AGI tools and foundational research in LLM. Let me discuss what was behind Nilekan's original 
opinion against pursuing Foundational Research on AI or Generative AI tools.

Many commentators have painted bleak scenarios about job losses due to the increasing use of AI-enabled tools. We have not yet seen 
much of its impact in the Indian context. Until now, AI's impacts have been restricted to secretarial assistance, education, healthcare,
and investment marketing, which involves human hand-holding. The assistance of AI tools has improved the capabilities of the average
human worker. The Indian government has been spending heavily on digital infrastructure since 2020 after the Covid-19 outbreak. 
Working from home and relying on contract-based jobs reduced costs for companies. However, many companies do not think working from 
home is acceptable. It allowed many employees to moonshine and engage in simultaneous jobs on contract for competing enterprises. At 
the individual level, managers and team leaders found that the employees ran into time management issues that affected productivity. 
Only the service industry grew during COVID-19, while the manufacturing sector suffered heavy losses. Government efforts to keep the 
economy afloat through extensive use of telecommunication and digital infrastructure led to the invasion of even bedrooms and restrooms of 
employees, creating an added schism in conflict in employee-employer relationship. Companies saw the opportunities in downsizing the 
workforce, eliminating deadwood, and preventing employees from moonshining. On the other hand, the employees were upset due to the 
employers' rampant unchecked invasion of personal space. With the introduction of AGI tools, we are about to witness another level of 
downsizing in the workforce and an increase in productivity.

Nelikani thinks that the government is well aware of this fact and is trying to direct AI research and development in 
retrieval augmented generation (RAG), which combines the strength of LLM with context-sensitive, precise knowledge. It will help
struggling employees meet the job requirements and, at the same time, make the employers happy with the workforce. The government's 
efforts are directed to accept the reality and work towards a win-win scenario. The government aims to raise the 
average happiness quotient for better economic growth. Let us analyze whether the strategy is well thought out or an attempt
to protect the stranglehold of Artificial General Intelligence (AGI) restricted only to a few big Tech companies. Incidentally,
Google Research Director Manish Gupta also concurs with Nelikani that Indian IT companies should invest in
building their AI tools.Nilekani's opinion has changed a bit from his original stance. Realizing that the government of India is 
seriously taking responsibility for creating computing infrastructure might have forced him to nuance his opinion. 
