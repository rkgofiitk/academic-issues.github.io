# Foundational AGI Tools from India: 

##  Myth vs Reality

[Blog Index](../index.md)

Earlier, late last year, Nandan Nelikani said that [Indian IT companies should not invest time and money in building LLM tools like ChatGPT
or Deep Seek](https://timesofindia.indiatimes.com/business/india-business/india-shouldnt-build-another-llm-nandan-nilekani/articleshow/116269605.cms).
Building a foundational model like ChatGPT is prohibitively expensive. Nilekani argued if Indian Companies have 50 billion USD to 
invest; they should instead use it to build computing infrastructure and an AI cloud.
These are resources for AI growth engines. The real challenge lies in making a tool scalable and affordable. With the release of
Deep Seek and the cost of building AI tools falling, Nelikani revised his stand a bit in 
[February 2025](https://economictimes.indiatimes.com/news/new-updates/why-infosys-co-founder-nandan-nilekani-feels-india-dont-need-a-china-type-deepseek-ai/articleshow/118528515.cms?from=mdr). 
"Foundation models like the ones that OpenAI and Meta are building often cost billions of dollars because they are being trained
on a vast amount of data requiring costly infrastructure." Both Nilekani and Narayan Murthy, Infosys co-founders, agree that Indian
tech companies have the expertise to build a foundational LLM tools like ChatGPT as the cost has come down. 

Going through a realistic estimate, it does not add up to back Deep Seek's official story is that its development cost is just 5.6 
million USD. The amount, in all fairness, represents only training costs. In 2019, Deep Seek founders spent 27.8 million USD to buy
1100 GPUs; they invested approximately 138 million USD in 2021 to develop their supercomputer cluster named Fire-Fly-2. So, the 
estimated infrastructure support cost alone could be more than 200 million USD. That may imply an estimated cost of anywhere from 500 
million to 1 billion USD. Usually, the cost of research, human resources, maintenance, electricity, cooling system,
and extensive experiments for building such a product are many times more than pure infrastructure cost. So, Nilekani revised his
stance nuancedly to accept that efforts to construct a foundational AI model may go hand-in-hand with use case AI application tools. 

[Manish Gupta, the head of Google research group in India](https://economictimes.indiatimes.com/tech/technology/google-research-india-head-disagrees-with-nandan-nilekani-says-india-must-build-llms/articleshow/115627015.cms) has been critical of Nandal Nelikani's view 
that India should not invest on foundational AI research. Manish thinks foundational research is more critical, generating
many out-of-the-box ideas to formulate use cases. He cites Aadhar as an example to prove the point that Nelikani himself created bases for
Aadhar rather than creating any associated tool as a test case. I gathered the following information about the contribution of
Manish Gupta's team in AI research from [Perplexity chatbot](https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research).
- Matryoshka representation learning inspired by Russian nesting dolls
- In making AI more affordable and accessible to rural masses in India
- Working for developing multimodal AI representation models over 100 indic languages,
- Working with AI startups to leverage insight from Google Deepmind
- Want researchers to develop breakthrough methods for advancing fusion energy leveraging AI
- Piloting IndicGenBench and supporting researchers as a leader
   
Manish Gupta is not one of the authors of either [Matryoksha](https://doi.org/10.48550/arXiv.2205.13147) or [IndicGenBench](https://arxiv.org/pdf/2404.16816) paper. 
The first paper's authors are drawn from Harvard University, Google Research, and the University of Washington. Four of them are from 
Google Research, who may belong to Manish Gupta's team. The authors of the second paper are from Google India Research. I am stating the 
facts I found different from the Perplexity search engine. The research inspired by the Russian Nesting Doll is an overstatement. The 
Peplexity's claim research paper that reported Matryoksha Representation
The learning paper uses the Nesting Russian Dolls as a metaphor to explain the model. Any nesting involves varying
degrees of granularity. It is a generic paradigm of gradual refinement of granularity of information and is independent of the Russian 
Nesting Dolls. Based on Manish Gupta's contributions and his position as a Senior Research Director in the Google Deepmind project
in India, I think his opinion carries weight and has to be taken seriously. I concur with Manish that any foundational research
trains students with the capabilities to develop cases without the limits of an example-based framework independently. No doubt both
Nilekani and Narayanmurthy, as successful founders of IT businesses in India, have established themselves as key voices among policymakers 
in the area. In comparison, Manish is younger and has not become an independent entrepreneur. So, the intent
in discussing Manish's background in the blog comes from having the experience and knowledge to proffer an opinion 
contrary to Nilekani's. 

I think the Indian Government AI Initiative aims to create an AI ecosystem. It is up to individual research groups and startups to 
use the infrastructure as they wish. In other words, the government's approach is more in line with the "Sky is the limit"  for pursuing 
ideas in developing AGI tools and foundational research in LLM. 

Let me discuss the reasoning behind Nilekan's original opinion against pursuing Foundational Research on AI or Generative AI tools.
Many commentators have painted bleak scenarios about job losses due to the increasing use of AI-enabled tools. We have not yet seen 
much of its impact in the Indian context. Until now, AI's impacts have been restricted to secretarial assistance, education, healthcare,
and investment banking, stock predictions or tasks that involve human hand-holding at the end of the chain. The assistance of AI tools
has enhanced the capabilities of the average human worker. The Indian government started spending heavily on digital infrastructure 
since 2020 after the Covid-19 outbreak. Working from home and relying on contract-based jobs reduced costs for companies. However, 
many companies do not think working from home is acceptable. It allowed many employees to moonshine and engage in simultaneous jobs 
on contract for competing enterprises. At the individual level, managers and team leaders found that the employees ran into time 
management issues that affected productivity. 

Only the service industry grew during COVID-19, while the manufacturing sector suffered heavy losses. Government efforts to keep the 
economy afloat through extensive telecommunication and digital infrastructure led to the invasion of even employees' bedrooms and 
restrooms, creating an added schism in conflict in the employee-employer relationship. Companies saw the opportunities in downsizing the 
workforce, eliminating deadwood, and preventing employees from moonshining. On the other hand, the employees were upset due to the 
employers' rampant unchecked invasion of personal space. With the introduction of AGI tools, we are about to witness another level of 
downsizing in the workforce and an increase in productivity.

Nelikani thinks that the government is well aware of this fact and is trying to direct AI research and development in 
retrieval augmented generation (RAG), which combines the strength of LLM with context-sensitive, precise knowledge. It will help
struggling employees meet the job requirements and, at the same time, make the employers happy with the workforce. The government's 
efforts are directed to accept the reality and work towards a win-win scenario. The government aims to raise the 
average happiness quotient for better economic growth. Let us analyze whether the strategy is well thought out or an attempt
to protect the stranglehold of Artificial General Intelligence (AGI) restricted only to a few big Tech companies. Incidentally,
Google Research Director Manish Gupta also concurs with Nelikani that Indian IT companies should invest in
building their AI tools. Nilekani's opinion has changed a bit from his original stance. Realizing that the government of India is 
seriously taking responsibility for creating computing infrastructure might have forced him to nuance his opinion. 

[Back to Index](../index.md)
