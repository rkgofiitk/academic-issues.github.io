# Foundational AGI Tools from India: 

##  Myth vs Reality

[Blog Index](../index.md)

Earlier, late last year, Nandan Nelikani said that [Indian IT companies should not invest time and money in building generic
LLM tools like ChatGPT or Deep Seek](https://timesofindia.indiatimes.com/business/india-business/india-shouldnt-build-another-llm-nandan-nilekani/articleshow/116269605.cms).
Nilekani argued that building a foundational model like ChatGPT is prohibitively expensive.  If Indian Companies have 50 billion
USD to invest; they should instead use it to build computing infrastructure and an AI cloud. The computing infrastructure and tools
are resources for AI growth engines. The real challenge lies in making a scalable and affordable AGI (Artificial General Intelligence) 
tool. With the release of Deep Seek and the cost of building AI tools falling, Nelikani revised his stand a bit in 
[February 2025](https://economictimes.indiatimes.com/news/new-updates/why-infosys-co-founder-nandan-nilekani-feels-india-dont-need-a-china-type-deepseek-ai/articleshow/118528515.cms?from=mdr). 
Foundation models like the ones that OpenAI and Meta are building, often cost billions of dollars because they require extensive
training on a vast amount of data that can be handled on costly infrastructure. Both Nilekani and Narayan Murthy, Infosys
co-founders, assert that Indian tech companies have the expertise to build a foundational LLM tools like ChatGPT as the cost has
come down. 

What exactly is the cost of building Deep Seek? Going through a realistic estimate, it does not add up to back Deep Seek's 
official story is that its development cost is just 5.6 million USD. The amount, in all fairness, represents only training costs. 
In 2019, Deep Seek founders ivested 27.8 million USD to buy 1100 GPUs; they spent approximately 138 million USD in 2021 to develop 
their supercomputer cluster named Fire-Fly-2. So, the estimated infrastructure support cost alone could be more than 200 million 
USD. That may imply an estimated cost of anywhere from 500 million to 1 billion USD. Usually, the cost of research, human 
resources, maintenance, electricity, cooling system, and extensive experiments for building such a product are many times more
than pure infrastructure cost. So, Nilekani nuanced his earlier stance to accept that efforts to construct a foundational AI model 
may go hand-in-hand with use case application tools. 

[Manish Gupta, the head of Google research group in India](https://economictimes.indiatimes.com/tech/technology/google-research-india-head-disagrees-with-nandan-nilekani-says-india-must-build-llms/articleshow/115627015.cms) has been critical of Nandan Nelikani's view. 
Manish thinks that the foundational research is more critical. Insight learned from research in building foundational AI models
helps generate many out-of-the-box ideas that will formulate use cases. He cites Aadhar as an example to prove the point that 
Nelikani himself created bases for Aadhar rather than creating any associated tool as a test case. I gathered the following 
information about the contribution of Manish Gupta's team in AI research from [Perplexity chatbot](https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research).
- Matryoshka representation learning inspired by Russian nesting dolls
- In making AI more affordable and accessible to rural masses in India
- Working for developing multimodal AI representation models over 100 indic languages,
- Working with AI startups to leverage insight from Google Deepmind
- Want researchers to develop breakthrough methods for advancing fusion energy leveraging AI
- Piloting IndicGenBench and supporting researchers as a leader
   
My intention of using an AI search engine is to understand its flexibilities and limitations. I thank 
[Preplexity](https://www.perplexity.ai/) team for extending a free pro-subscription. Now to facts about Manish Gupta's 
credentials as a Senior Google Research Director. He supported many research initiatives in Google India though he himself 
is not one of the authors of either of the papers [Matryoksha](https://doi.org/10.48550/arXiv.2205.13147) or 
[IndicGenBench](https://arxiv.org/pdf/2404.16816). The first paper's authors are drawn from Harvard University, Google Research, 
and the University of Washington. Four of them are from Google Research, who belong to Manish Gupta's team. The authors of the 
second paper are from Google India Research. Perplexity search engine says that the Matryoksha Representation was inspired by
the Russian Nesting Doll. The paper uses the Nesting Russian Dolls only as a metaphor to explain the model. Nesting 
is a technique to represent varying degrees of granularity. It is a generic paradigm of gradual refinement of information 
granularity. Based on Manish Gupta's indirect contributions and his position as a Senior Research Director in the Google 
Deepmind project in India, I think his opinion carries a lot of weight. I concur with Manish that any foundational research
trains students with the capabilities to develop cases without the limits of an example-based framework independently. No doubt
both Nilekani and Narayanmurthy, as successful founders of IT businesses in India, have established themselves as key voices
in shaping up IT research in the country. In comparison, Manish is younger and has not sweted as an independent entrepreneur. 
Therefore, the intent in discussing Manish's background in the blog comes from having the experience and knowledge to proffer 
an opinion contrary to Nilekani's. 

I think the Indian Government AI Initiative aims to create an AI ecosystem. It is up to individual research groups and startups to 
use the infrastructure as they wish. In other words, the government's approach is more in line with the "Sky is the limit"  for 
pursuing ideas in developing AGI tools and foundational research in LLM. The government is keenly focused in its role as an
enabler rather than enforcing its role as direction setter. 

There is, however, a lot merit in Nilekan's original opinion against pursuing Foundational Research on AI or Generative AI tools.
Many commentators have painted bleak scenarios about job losses due to the increasing use of AI-enabled tools. We have not yet seen 
much of its impact in the Indian context. Until now, AI's impacts have been restricted to secretarial assistance, education, 
healthcare, and investment banking, stock predictions or tasks that involve human hand-holding at the end of the chain. The 
assistance of AI tools has enhanced the capabilities of the average human worker. The Indian government started spending heavily 
on digital infrastructure since 2020 after the COVID-19 outbreak. Working from home and relying on contract-based jobs reduced
costs for companies. However, many companies do not think working from home is acceptable. Wipro, Cognizant, Infosys, L&T 
have strictly advised staff to report physically. They strongly suspect work from home allows productive employees to moonshine 
and engage in simultaneous jobs on contract for competing enterprises. At the individual level, managers and team leaders found 
that the employees ran into time management issues that affected productivity. 

Only the service industry grew during COVID-19, while the manufacturing sector suffered heavy losses. Government efforts to keep the 
economy afloat through extensive telecommunication and digital infrastructure led to the invasion of employees' bedrooms and even 
restrooms, creating a fresh schism in conflict in the employee-employer relationship. Companies saw the opportunities in downsizing 
the workforce, eliminating deadwood, and ploys to prevent employees from moonshining. On the other hand, the employees were upset 
due to rampant unchecked invasion of personal space by supervisors or team leaders. With the introduction of AGI tools, we are 
about to witness another level of downsizing in the workforce and an increase in productivity. Probably the idea behind Nilekani's 
opinion on concentrating research on AGI tools is to reduce system-inefficiency in India. However, I believe it is a misplaced 
idea. The employers will leverage AGI applications for eliminating workforce from different sectors and lead to large-scale 
unemployment. The competence level is not limited human capabilities but to the inherent laziness in human characteristics. In a 
sense Nilekani's opinion reflects the opinion of [Raghuram Rajan who wanted India to only focus in service sector](https://uwm.edu/business/reimagining-development-possible-lessons-from-india/).


Nelikani believes that the government is well aware of this fact and is trying to guide AI research and development in 
retrieval augmented generation (RAG), which combines the strength of LLM with context-sensitive, precise knowledge. It will help
struggling employees meet the job requirements and, at the same time, make the employers happy with the workforce. The government's 
efforts are to accept the reality and work towards a win-win scenario. The focus of a good governance will be to raise the 
average happiness quotient for better economic growth. So, a government should act as an enabler rather than an enforcer.
 strategy is well thought out or an attempt
to protect the stranglehold of Artificial General Intelligence (AGI) restricted only to a few big Tech companies. Incidentally,
Google Research Director Manish Gupta also concurs with Nelikani that Indian IT companies should invest in
building their AI tools. Nilekani's opinion has changed a bit from his original stance. Realizing that the government of India is 
seriously taking responsibility for creating computing infrastructure might have forced Nandan Nilekani to nuance his opinion. 

[Back to Index](../index.md)
