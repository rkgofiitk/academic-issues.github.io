# Any Indian Competitor of Deep Seek?

##  Myth vs Reality

[Blog Index](../index.md)

Earlier, late last year, Nandan Nelikani said that Indian IT companies should not invest time and money in building a generic
LLM tools like ChatGPT or Deep Seek. Nilekani argued that building a foundational model like [ChatGPT is prohibitively expensive](https://timesofindia.indiatimes.com/business/india-business/india-shouldnt-build-another-llm-nandan-nilekani/articleshow/116269605.cms). 
If Indian companies have 50 billion USD in investment, they should instead use it to build computing infrastructure and an AI cloud.
The computing infrastructure and tools are resources for AI growth engines. The real challenge lies in making a scalable and 
affordable AGI (Artificial General Intelligence) tool. With the release of Deep Seek and the cost of building AI tools falling, 
Nelikani revised his stand a bit in [February 2025](https://economictimes.indiatimes.com/news/new-updates/why-infosys-co-founder-nandan-nilekani-feels-india-dont-need-a-china-type-deepseek-ai/articleshow/118528515.cms?from=mdr). 
Foundation models like the ones that OpenAI and Meta are building often cost billions of dollars because they require extensive
training on vast data that can be handled only by costly computing infrastructure. Nilekani and Narayan Murthy, Infosys
co-founders, assert that Indian tech companies have the expertise to build foundational LLM tools like ChatGPT as the cost has
come down. 

Before elaborating further, let us get a realistic estimate of the cost of building Deep Seek. Deep Seek's 
official disclosure is that its development cost is just 5.6 million USD. In all fairness, experts believe that the reported 
cost represents only the execution of model training runs. The typical cost factors are:
- Research and development for generating synthetic data needed for training the model 
- Executing multiple training runs with diverse data sets to validate results
- Collection and preparing pretraining can also be expensive

The execution of the above tasks requires significant computing resources. In 2019, Deep Seek founders invested 27.8 million USD
to buy 1100 GPUs; they spent approximately 138 million USD in 2021 to develop their supercomputer cluster named Fire-Fly-2. The estimated cost for building computing infrastructure alone would be more than 200 million USD. A CNBC report
says that the cost could exceed well over [500 million to 1 billion USD](https://www.cnbc.com/2025/01/31/deepseeks-hardware-spend-could-be-as-high-as-500-million-report.html).
The above cost estimate may exclude maintenance, electricity, cooling system, and many unsuccessful iterative executions
and extensive experiments, which would be many times more than the infrastructure cost. In the case of ChatGPT and other
competing products, the cost of the training component is around 20 million USD. Therefore, Deep Seek is 50% cheaper than its other competitors. With costs decreasing drastically, Nilekani nuanced his earlier stance to accept that efforts to 
construct a foundational AI model may go hand-in-hand with use case application tools. 

Manish Gupta, the head of the Google research group in India, has been [critical of Nandan Nelikani's view](https://economictimes.indiatimes.com/tech/technology/google-research-india-head-disagrees-with-nandan-nilekani-says-india-must-build-llms/articleshow/115627015.cms). 
Manish thinks that the foundational research is more critical. Insight learned from research in building foundational AI models
helps generate many out-of-the-box ideas to formulate use cases. He cites Aadhar as an example to prove the point that 
Nelikani created bases for Aadhar rather than creating any associated tool as a test case. I gathered the following 
information about the contribution of Manish Gupta's team in AI research from [Perplexity chatbot](https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research).
- Matryoshka representation of learning inspired by Russian nesting dolls
- In making AI more affordable and accessible to rural masses in India
- Working for developing multimodal AI representation models over 100 indic languages,
- Working with AI startups to leverage insight from Google Deepmind
- Want researchers to develop breakthrough methods for advancing fusion energy leveraging AI
- Piloting IndicGenBench and supporting researchers as a leader
   
My intention in using an AI search engine was to understand its flexibilities and limitations. I thank 
[Preplexity](https://www.perplexity.ai/) team for extending a free pro-subscription. Manish Gupta's credentials as a senior Google 
India Research Director are well-known. He supported many research initiatives in Google India, though he is not one of the authors 
of either of the papers [Matryoksha](https://doi.org/10.48550/arXiv.2205.13147) or [IndicGenBench](https://arxiv.org/pdf/2404.16816). 
The first paper's authors are drawn from Harvard University, Google Research, 
and the University of Washington. Four are from Google Research and belong to Manish Gupta's team. The authors of the 
second paper are from Google India Research. The perplexity search engine says that the Russian Nesting Doll inspired the Matryoksha 
Representation. The paper uses the Nesting Russian Dolls only as a metaphor to explain the model. Nesting 
is a technique to represent varying degrees of granularity. It is a generic paradigm of gradual refinement of information 
granularity. Manish  Gupta's opinion carries a lot of weight, considering his indirect contributions as a Senior Research Director of 
the Google Deepmind project in India. I concur with Manish that any foundational research
trains students with the capabilities to develop cases without the limits of an example-based framework independently. No doubt, both 
Nilekani and Narayanmurthy, as successful founders of IT businesses in India, have established themselves as key voices
in shaping IT research in the country. In comparison, Manish is younger and has not sweated as an independent entrepreneur. 
Therefore, the intent in discussing Manish's background in the blog comes from having the experience and knowledge to proffer 
an opinion contrary to Nilekani's. 

I think the Indian Government AI Initiative aims to create an AI ecosystem. It is up to individual research groups and startups to 
use the infrastructure as they wish. In other words, the government's approach aligns more with the "Sky is the limit"  for 
pursuing ideas in developing AGI tools and foundational research in LLM. The government is keenly focused on its role as an
enabler rather than enforcing its role as a direction setter. 

There is, however, a lot of merit in Nilekan's original opinion against pursuing Foundational Research on AI or Generative AI tools.
Many commentators have painted bleak scenarios about job losses due to the increasing use of AI-enabled tools. We have not yet seen 
much of its impact in the Indian context. Until now, AI's impacts have been restricted to secretarial assistance, education, 
healthcare, investment banking, stock predictions, or tasks that involve human hand-holding at the end of the chain. The 
assistance of AI tools has enhanced the capabilities of the average human worker. The Indian government started spending heavily 
on digital infrastructure in 2020 after the COVID-19 outbreak. Working from home and relying on contract-based jobs reduced
costs for companies. However, many companies do not think working from home is acceptable. Wipro, Cognizant, Infosys, and L&T 
have strictly advised staff to report physically. They strongly suspect that working from home allows productive employees to
moonshine and engage in simultaneous jobs on contract for competing enterprises. At the individual level, managers and team 
leaders found that the employees ran into time management issues that affected productivity. 

Only the service industry grew during COVID-19, while the manufacturing sector suffered heavy losses. Government efforts to keep the 
economy afloat through extensive telecommunication and digital infrastructure led to invading employees' bedrooms and even 
restrooms, creating a new conflict in the employee-employer relationship. Companies saw the opportunities in downsizing 
the workforce eliminating deadwood and ploys to prevent employees from moonshining. On the other hand, the employees were upset 
due to the rampant, unchecked invasion of personal space by supervisors or team leaders. With the introduction of AGI tools, we are 
about to witness another level of downsizing in the workforce and an increase in productivity. Nilekani's 
opinion on concentrating research on AGI tools is to improve system efficiency in India. Manish Gupta also concurs with Nelikani
that Indian IT companies should invest in building their AI tools. However, it is a misplaced idea. Employers 
will leverage AGI applications to eliminate the workforce from different sectors, leading to large-scale unemployment. The 
competence level is not limited to human capabilities but to the inherent laziness in human characteristics. In a sense, Nilekani's
opinion reflects the opinion of Raghuram Rajan, who wants India to focus only on [service sector](https://uwm.edu/business/reimagining-development-possible-lessons-from-india/).

Nelikani believes that the government is well aware of this fact and is trying to guide AI research and development in 
retrieval augmented generation (RAG), which combines the strength of LLM with context-sensitive, precise knowledge. It will help
struggling employees meet the job requirements and, at the same time, make the employers happy with the workforce. So, AGI
is seen as a tool to raise service efficiency. The government, however, understood its role as an enabler or facilitator. 
It has decided to spend 10k crores on establishing AI infrastructure. Good governance will focus on raising the 
average happiness quotient for better economic growth. However, knowing how access to any well-intentioned government 
facility works, bureaucracy will dictate a policy to access the facility that may eventually protect the
stranglehold of a few big Tech companies. Therefore, independent research groups need to keep 
research on foundational AI models. 

[Back to Index](../index.md)
