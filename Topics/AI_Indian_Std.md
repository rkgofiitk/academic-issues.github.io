# Indian IT Companies versus AI Revolution

Earlier, late last year Nandan Nelikani said that [Indian IT companies should not invest time and money on building LLM tools like ChatGPT
or Deep Seek](https://timesofindia.indiatimes.com/business/india-business/india-shouldnt-build-another-llm-nandan-nilekani/articleshow/116269605.cms).
Building a foundational model like ChatGPT is prohibitively expesive requiring upwards 500 million USD. Nilekani argued if 
Indian Companies have 500 million USD to invest, they should rather use it for building computing infrastructure, and AI cloud.
These are material for AI growth engines. The real challenge lies in making the tool scalable 
and affordable. With release of Deep Seek and the cost of builiding AI tools falling, [Nelikani revised his stand in 
February 2025](https://economictimes.indiatimes.com/news/new-updates/why-infosys-co-founder-nandan-nilekani-feels-india-dont-need-a-china-type-deepseek-ai/articleshow/118528515.cms?from=mdr). 
Both Nilekani and Narayanmurthy Infosys co-founders agree that Indian tech companies have expertise to build a foundational
LLM tool like ChatGPT as the cost has come down. However, going through a realistic estimate, it does not add up to  basck
the Deep Seek's official story that its development cost is just 5.6 million USD. The amount in all fairness represents only
training cost. In 2019, Deep Seek founders spent 27.8 million USD to buy 1100 GPUs, they invested approximately 138 million 
USD in 2021 for developing their super computer cluster named Fire-Fly-2. So estimated infrastructure support cost alone 
could be more than 200 million USD. That may imply estimated cost anywhere in the range of 500 million to 1 billion USD. Usually,
the cost on research, manpower, maintenance, electricity, cooling system, extensive experiments for building such a 
product are many times more than pure infrastructure cost. I guess, both the captains of IT industries in India may want to 
review their stance more cautiously than over-enthusiastically. 

[Manish Gupta, the head of Google research group in India](https://economictimes.indiatimes.com/tech/technology/google-research-india-head-disagrees-with-nandan-nilekani-says-india-must-build-llms/articleshow/115627015.cms) has been a critical of Nandal Nelikani's view 
that India should not invest on foundational AI research. Manish thinks foundational research is more important, as it generates
host of ideas to formulate use cases. He cites Aadhar as an example to proof the point that Nelikani himself created bases for
Aadhar rather than creating any associated tool as a test case. I gathered the following information about contribution of
Manish Gupta's team in AI research from [Perplexity chatbot](https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research).
- [Matryoshka representation learning inspired by Russian nesting dolls](https://doi.org/10.48550/arXiv.2205.13147)
- In making AI more affordable accessible to rural mass in India
- Working for developing multimodal AI representation models over 100 indic languages,
- Working with AI startups to leverage insight from Google Deepmind
- Want researchers to develop breakthrough methods for advancing fusion energy leveraging AI
- Piloting IndicGenBench and supporting researchers as a leader
   
In reality, Manish Gupta is not one of the authors either Matryoksha or [IndicGenBench](https://arxiv.org/pdf/2404.16816) paper. 
The authors the first paper are drawn from Harvard University, Google Research and University of Washington. Four of them are from 
Google Research who may possibly belong to Manish Gupta's team. The authors of the second paper are from Google India Research and
also possibly from Manish Gupta's team. I am just stating the facts I found different from Perplexity search engine. Now about the
research being inspired by Russian Nesting Doll appears a bit unreal. The research paper that reported Matryoksha Representation
Learning paper uses the Nesting Russian Dolls as a metaphor to explain the model. My contention is that any nesting involves varying
degree of granularity. It is a generic paradigm of gradual refinement of granularity of information and independent of Russian 
Nesting Dolls. On the basis of Manish Gupta's contributions and his position as a Senior Research Director in Google Deepmind project
in India, I think his opinion carries waight and has to be taken seriously. I concur with Manish that any foundational research
trains student with capabilities to independently evelove usecases without the limits of example based framework. No doubt 
Nilekani and Narayanmurthy as successful IT founders have established themselves as key voices in the area. In comparison Manish
is not only younger but has not ventured as an independent enterpreneaur. So, the intent in discussing Manishes background in the blog 
comes from the fact that he has exeperience and knowledge to proffer an opinion contrary to Nilekani. 

I think Indian Government AI Initiative aims to create an AI-echosystem. It is upto individual research groups, and startups to 
use the infrastructure as they wish. In other words, the government has set "Sky is limit" model in pursuits of ideas in developing
AGI tools and foundational research in LLM. Let me discuss a bit on what was behind Nilekan's orginal opinion against pursuing
of Foundational Research on AI or Generative AI tools.

Many commentators have painted bleak scenarios about job losses due to increasing use of AI enabled tools, we have not yet seen 
much of its impact in Indian context. AI's impacts until now have been restricted in secretarial assistances, education, healthcare,
investment marketing with human hand-holding. Asistance of AI tools has improved capabilities of average human worker. Indian
government has started speding heavily in digital infrastructure since 2020 after Covid-19 outbreak. Work from home, and relying on
contract based jobs reduced cost to companies. However, many companies did not think work from home is a great idea. It allowed
many employee to moonshine working for many simultaneous jobs on contract. At individual level, managers and team leaders found
that the employees ran into time management affecting productivity. Only service industry grew during Covid-19 while manufacturing 
sector suffered heavy losses. Government efforts to keep economy afloat through extensive use of telecommunication and digital 
infrastructure led to invasion of even bedrooms and restroom of employees created an added schism in conflict in employee-employer 
relationship. Companies saw the opportunities in downsizing the workforce, eliminating deadwoods, and preventing employees from 
moonshining.The employees, on the other hand, were upset due to rampant unchecked invasion of personal space by the employers. 
WIth introduction of AGI tools, we are about to witness another level of downsizing in workforce and increase of productivity.

Nelikani thinks that the government is well aware of the fact and trying to direct the AI research and development in the area of
retrieval augmented generation (RAG) which combines the strength of LLM with context sensitive, precise knowledge. It will help
struggling employees to meet the job requirements and at the same time make the employers happy with workforce. The government 
efforts are directed to accept the reality and work towards a win-win scenario. The government's idea is to raise the 
average happiness quotient for a better econonmic growth. Let us analyize whether the strategy is well thought out or an attempt
to ensure preserve stranglehold of Artificial General Intelligence (AGI) restricted only to a few big Tech companies. Incidentally,
Google Research Director Manish Gupta also concurs with Nelikani to the extent that Indian IT companies should invest in
building their AI tools. Nilekani opinion has changed in last  RAG
tools .  
