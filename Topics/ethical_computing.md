# Crisis of Ethics in Computing

[Blog Index](../index.md)


CACM January 2025 issue carries an insightful discussion on the "Crisis of Ethics" in computing by Moshe Vardi. Vardi candidly expresses the significant
change in his view on the "crisis of ethics" in computing. The article begins with a quote from Wall Street columnist Peggy Noonan
after the Guardian and the New York Times broke the story on Cambridge Analytica's engineered data breach of Facebook. Noonan quipped that the
Silicon Valley executives consider themselves "moral Martians who operate on some weird new postmodern ethical wavelength." Niall Ferguson,
a Hoover Institution historian described cyberspace as "Cyberia (parody of Syberia), a dark and lawless realm where malevolent actors range." 
The outrages of the two commentators were in the context of Cambridge Analytica's successful business model built on the harvested demographic
data in elections of the US, India, and other countries by large-scale hacking of Facebook.

Cambridge Analytica is a British political consulting company that was established in 2013. It could micro-target people on Facebook from 2010 and rolled out an
open graph with the associated APIs that can access data and features from one application to another. Cambridge Analytica's model was developed using
90 million Facebook users. The developer can see the connection between people, social groups, activities, interests, demographic attributes, etc., using their 
API. In 2014, employees and contractors of Cambridge Analytica were trying to sell psychological profiles of American voters to political campaigns.
In a companion report, it was claimed that Cambridge Analytica and its British affiliate SCI group were in touch with executives of Lukoil,
a Russian oil giant. Lukoil was interested in the way Americans may vote. Obama's campaign reportedly developed an application that connected 
Obama's supporters to his potential supporters. Cambridge Analytica also meddled with the Indian election. On 27th March 2018, the Times of India 
reported that the company worked extensively with the Congress Party for the Indian Election as per whistleblower 
[Christopher Wylie's testimony](https://timesofindia.indiatimes.com/india/whistleblower-names-congress-as-client-of-cambridge-analytica/articleshow/63491689.cmsin) 
in the British Parliament. 

A Cambridge University researcher, Aleksandar Kogan, used the Cambridge Analytica API tool to determine what may affect the behavior of Facebook users. 
Kogan shared his research data with Cambridge Analytica. It is unclear how Cambridge Analytica benefitted from Kogan's research. But I suspect
it might have opened avenues for large-scale unethical computing, which can influence a country's political power structure and make them permanently 
unstable due to the business models of big tech companies.

Vardi's article further narrates the story of Uber centered around its founder, Tarvis Kalanick. In 2023, Kalanick was lauded
as a person who made affordable services available to a large user base. According to a report from a popular magazine, "... Travis Kalanick had built
an enormous, enthusiastic user base by subsidizing rides with the company's vast reservoir of VC funding. Under Kalanick, Uber skirted regulations, 
shrugged off safety issues, and presided over a workplace rife with sexual harassment."  A whistleblower exposed Kalanick's misdeeds, who leaked over 
124,000 company files to the Guardian. 

Both Cambridge Analytica and Uber's stories about unethical computing were driven by profit motivation. Is profit motivation against public good? 
Moshe's article quotes [Adam Smith](https://en.wikipedia.org/wiki/Adam_Smith), a Scottish philosopher and economist of 18th century who pioneered 
thinking in political economy and said that "They are led by an invisible hand ...and thus without intending it, without knowing it, advance the interest 
of the society." Vardi opines that Adam Smith's "free market always serves public good" theory has no theoretical basis. 
He said, "Climate crisis has demonstrated the failure of the free market." Similarly, big tobacco companies are not working for the public good.
Moshe Vardi's article presents "ethical practices" as the thin line between the free market and the public good. A crisis of ethics can be devastating 
if one chooses to extend the theory of the free market or unfettered business models on top of AI/ML and big data analytics in the guise of public good.

Returning to the crisis of ethics in computing, let us draw a parallel from unethical nuclear research. While nuclear power reactors led to 
energy sufficiency, reduction of carbon footprint, and cancer treatment, the atomic explosion was responsible for unimaginable holocausts like Nagasaki and
Hiroshima. About nine countries, including India, now possess nuclear weapon capabilities. Yet, there has not been a single use of nuclear weapons after 1945. 
Many commentators argue that nuclear capabilities act more as a deterrent than destruction. I don't know how Moshe Vardi will view this analogy concerning unethical computing. US President Roosevelt, who ordered the dropping of a nuclear bomb in 1945, was the most popular US President. He was elected 
four times and probably would have ruled the US for 20 years had he been a little younger and did not die 2 years into his fourth term. Interestingly, US 
The Constitution was amended after Roosevelt. The question is: why do US citizens think Roosevelt was so good? Does it mean most US citizens suffer from
a crisis of ethics? 

I believe that scientific research should not be shackled. Almost all will agree that all religions strongly support the practice of ethics in all spheres
of human society, including scientific research. Science and theology have often coexisted in harmony. The conflicts between Galileo and Copernicus with
The church is well documented. Catholic Church banned Copernicus's theory and warned Galileo, but it could or did not stop the direction of scientific research.
According to a [pew research document](https://www.pewresearch.org/science/2020/08/26/on-the-intersection-of-science-and-religion/), the conflict between
science and religion is mainly hyped. While Hindus think science and theology are complementary spheres, Buddhists isolate the two spheres. However, 
Buddhists cannot identify any scientific research that comes in the way of their religious scriptures. Muslims say that science and Islam are generally 
compatible, though some areas of science, like evolutionary theory, conflict with their religious beliefs.  

Moshe Vardi quotes political activist Upton Sinclair. Sinclair states, "It is difficult for a person to understand something when their salary depends on
not understanding it." Vardi feels that big tech workers do not ask hard questions, which they should be asking especially about the business models 
the company wants to pursue. In conclusion, there is a severe ethical crisis in computing. I don't know if Vardi will push for a course in ethics as
a part of the computer science course curriculum. However, no amount of courses or teaching will ever eliminate the crisis of ethics in any field
of human life. Ethics and worldly requirements for existence are orthogonal issues in an ordinary person's life. So, we cannot say that
the responsibility of ethical computing should be on the salaried workers of Big Tech companies.

The crisis of ethics in computing has not attained its defining proportion yet. It will show up in much larger proportions in use of automated tools
with applications of AI research. These tools may ultimately control the entire ecosystem around human society and civilization. It is difficult to 
foresee the kind of intervention that AI applications may have in the future. However, as every research study has pros and cons, many researchers will work on 
counter strategies to preserve ethics. For example, we once thought Wintel would dictate computing, but open source ensured computing was not
overwhelmed by Microsoft and Intel. 


I believe crisis of ethics in computing has not attained its defining proporation yet. It will show up in much more larger proportions in applications of 
AI research in building automated tools that may affect entire ecosystem around human society and civilization. It is difficult to foresee the kind of
intervantion that AI application may have in future. However, like every research has pros and cons, I am sure that many researchers will work on 
counter strategies for preseerving ethics. For example, at one time we thought wintel will dictate computing, but open source ensured computing is not
overwhelmed by Microsoft and Intel. 

[Back to Index](../index.md)

