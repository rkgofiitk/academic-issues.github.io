# Crisis of Ethics in Computing

[Blog Index](../index.md)


CACM January 2025 issue carries an insightful discussion on the "Crisis of Ethics" in computing by Moshe Vardi. Vardi candidly expresses the significant
change in his view on the "crisis of ethics" in computing. The article begins with a quote from Wall Street columnist Peggy Noonan
after the Guardian and the New York Times broke the story on 's  breaching of Facebook data engineered by Cambridge Analytica. Noonan quipped that the
Silicon Valley executives consider themselves "moral Martians who operate on some weird new postmodern ethical wavelength." Niall Ferguson,
a Hoover Institution historian, described cyberspace as "Cyberia, a dark and lawless realm where malevolent actors range" 
The outrages of the two commentators were in the context of Cambridge Analytica's business model built on the harvested demographic
data for influencing election outcomes in the US, India, and other countries.

Cambridge Analytica is a British political consulting company established in 2013. It could micro-target people on Facebook from 2010 and roll out an
open graph alongwith the associated APIs that can access data and features from one application to another. Cambridge Analytica's model was developed using
90 million Facebook users. The developer can see the connection between people, social groups, activities, interests, demographic attributes, etc., using their 
API. In 2014, employees and contractors of Cambridge Analytica were reportedly trying to sell psychological profiles of American voters to political campaigns.
In a companion report, it was claimed that Cambridge Analytica and its British affiliate SCI group were in touch with executives of Lukoil,
a Russian oil giant. Lukoil was interested in the way Americans may vote. Obama's campaign reportedly developed an application that connected 
Obama's supporters to his potential supporters. Cambridge Analytica also meddled with the Indian election. On 27th March 2018, the Times of India 
reported that the company worked extensively with the Congress Party for the Indian Election quoting the whistleblower 
[Christopher Wylie's testimony](https://timesofindia.indiatimes.com/india/whistleblower-names-congress-as-client-of-cambridge-analytica/articleshow/63491689.cmsin) 
in the British Parliament. 

A Cambridge University researcher, Aleksandar Kogan, used the Cambridge Analytica API tool to determine what may affect the behavior of Facebook users. 
Kogan shared his research data with Cambridge Analytica. It is unclear how Cambridge Analytica benefitted from Kogan's research. But I suspect
it might have opened avenues for large-scale unethical computing, which can influence a country's political power structure and make them permanently 
unstable. So big Tech companies could effectively exert political influence in governance through unethical computing techniques and the associated business models.

Vardi's article further narrates the story of Uber founder, Tarvis Kalanick. Kalanick was lauded
for making affordable services available to a large user base. In 2023, according to a report from a popular magazine, "... Travis Kalanick had built
an enormous, enthusiastic user base by subsidizing rides with the company's vast reservoir of VC funding. Under Kalanick, Uber skirted regulations, 
shrugged off safety issues, and presided over a workplace rife with sexual harassment."  A whistleblower exposed kalanick's misdeeds, who leaked over 
124,000 company files to the Guardian. 

Both Cambridge Analytica and Uber's stories about unethical computing were driven by profit motivation. Is profit motivation unethical? 
Moshe's article quotes [Adam Smith](https://en.wikipedia.org/wiki/Adam_Smith), a Scottish philosopher and economist of the 18th century who pioneered 
thinking in political economy and said that "They are led by an invisible hand ...and thus without intending it, without knowing it, advance the interest 
of the society." Vardi opines that Adam Smith's "free market always serves public good" theory has no theoretical basis. 
He said, "Climate crisis has demonstrated the failure of the free market." Similarly, big tobacco companies are not working for the public good.
Moshe Vardi's article presents "ethical practices" as the thin line between the free market and the public good.  If we choose to extend the theory of the free
market or unfettered business models on the top of AI/ML techniques and big data analytics in the guise of public good it can lead to devastating consequences.
This intense urge for profit motivation by big Tech companies has indeed lead us to that a "crisis of ethics" in computing. 

Crisis of ethics also effects exploitation of scientific discoveries for public good. Let us draw a parallel from unethical nuclear research. Nuclear power reactors led to 
energy sufficiency, reduction of carbon footprint, and cancer treatment. At the same time the atomic explosion was responsible for unimaginable holocausts like Nagasaki and
Hiroshima which resulted in death of over a million and hald. About nine countries, including India, now possess nuclear weapon capabilities. Yet, there 
has not been a single use of nuclear weapons after 1945. Many commentators argue that nuclear capabilities act more as a deterrent than destruction. I don't 
know how Moshe Vardi will view this analogy concerning unethical computing. US President Roosevelt, who ordered the dropping of atom bombs in 1945, was the most 
popular US President. He was elected four times and probably would have ruled the US for 20 years had he been a little younger and did not die 2 years 
into his fourth term. Interestingly, the US Constitution was amended after Roosevelt. The question is: why do US citizens think Roosevelt was so good? 
Does it mean most US citizens suffer from a crisis of ethics? 

Scientific research should not be shackled. Almost all will agree that all religions strongly support the practice of ethics and morality in all spheres
of human society, including scientific research. Science and theology have often coexisted in harmony. Church is known to have collaborated and sponsored science.
However, the conflicts between Galileo and Copernicus with the church is well documented. Catholic Church banned Copernicus's theory and warned Galileo, 
but it could or did not stop the direction of scientific research. According to a [pew research document](https://www.pewresearch.org/science/2020/08/26/on-the-intersection-of-science-and-religion/), 
the conflict between science and religion is mainly hyped. The report was based on interviewing volunteers from Hindu, Muslim, and Budhisist. While Hindus 
think science and theology are overlapping spheres. Hindu scriptures include elements of science and identified concepts now being validated by science.  Buddhists isolate the two spheres. However, Buddhist interviewees did not identify any scientific research that comes in the way of their religious scriptures. 
Muslim interviewees thought that science and Islam are generally compatible, though some areas of science, like evolutionary theory, conflict with their religious beliefs.  

Moshe Vardi quotes political activist Upton Sinclair. Sinclair states, "It is difficult for a person to understand something when their salary depends on
not understanding it." Vardi feels that big tech workers do not ask hard questions, which they should be asking, especially about the business models. 
In conclusion, there is a severe ethical crisis in computing. I don't know if Vardi will push for a course in ethics as a part of the computer science 
course curriculum. However, no amount of courses or teaching will ever eliminate the crisis of ethics in any sphere of human life. Ethics and worldly 
requirements for existence may at times work in cross purposes in life of an ordinary person. So, it is unfair to place the responsibility of ethical computing 
on the salaried workers of Big Tech companies. 

The crisis of ethics in computing has not attained its defining proportion yet. It will show up in much larger proportions using automated tools
with AI research applications. These tools may ultimately control the entire ecosystem around human society and civilization. It is difficult to 
foresee the kind of intervention that AI applications may have in the future. Every research study has its pros and cons. Many researchers 
work on counter strategies to preserve ethics. Research in computer security, privacy, and surveillance is a defense mechanism against
unauthorized exploitations of person-centric or organization-centric data breaches. However, I agree with Moshe that vested interests often foist 
counter strategies for ulterior purposes. For example, take the case of Elon Musk, one of the six co-founders of [OpenAI](https://www.techopedia.com/who-owns-openai). 
His AI ambitions were overshadowed by his numerous interests like Spacex, tesla, and starlinks. He resigned from the openAI board in 2018. 
However, Musk brought a lawsuit accusing Sam Altman of abandoning the avowed humanitarian goal of OpenAI. Sam was ousted from the CEO's post in late 2023 
for four days. As neutral observers on the sidelines, we can neither believe nor disbelieve the accusation in Musk's lawsuit. It only reinforces our
thesis that the dynamics of the free market are beyond the control of ordinary citizens though it may be against "public good" at times. 


[Back to Index](../index.md)

